{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reliable-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect mysql\n",
    "import pymysql\n",
    "conn = pymysql.connect(host = 'localhost', user='dongyeon0317', password='1Q2w3e4r!@', db='crime_prediction', charset = 'utf8')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "massive-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Spring 2.Summer 3.Fall 4.Winter 1\n",
      "1.Morning 2.Afternoon 3.Evening 4.Midnight 1\n",
      "1.눈/비 2.맑음 3.흐림 1\n"
     ]
    }
   ],
   "source": [
    "# select from Dataset - Choose scenario\n",
    "\n",
    "# Season\n",
    "num = int(input('1.Spring 2.Summer 3.Fall 4.Winter '))\n",
    "if num == 1: season = 'Spring'\n",
    "elif num == 2: season = \"Summer\" \n",
    "elif num == 3: season = \"Fall\" \n",
    "else: season = \"Winter\"\n",
    "\n",
    "# Time    \n",
    "num = int(input(\"1.Morning 2.Afternoon 3.Evening 4.Midnight \"))\n",
    "if num == 1: time = \"Morning\"  \n",
    "elif num == 2: time = \"Afternoon\" \n",
    "elif num == 3: time = \"Evening\" \n",
    "else: time = \"Midnight\"\n",
    "    \n",
    "# Weather    \n",
    "num = int(input(\"1.눈/비 2.맑음 3.흐림 \"))\n",
    "if num == 1: \n",
    "    where = 'WHERE (season = \\''+ season + '\\' and time = \\'' + time + '\\' and rainfall > 0) or (season = \\'' + season + '\\' and time = \\'' + time + '\\' and snowfall > 0);' \n",
    "elif num == 2: \n",
    "    where = 'WHERE (season = \\''+ season + '\\' and time = \\'' + time + '\\' and rainfall = 0 and cloud < 5) or (season = \\'' + season + '\\' and time = \\'' + time + '\\' and snowfall = 0 and cloud < 5);' \n",
    "else: \n",
    "    where = 'WHERE (season = \\''+ season + '\\' and time = \\'' + time + '\\' and rainfall = 0 and cloud >= 5) or (season = \\'' + season + '\\' and time = \\'' + time + '\\' and snowfall = 0 and cloud >= 5);' \n",
    "\n",
    "dataset_sql = 'SELECT grid, CCTV_num, police_value, resident, floating FROM Dataset ' + where\n",
    "grid_sql = 'SELECT grid, CCTV_num, police_value, resident, floating FROM Grid WHERE time = \\''+ time + '\\''\n",
    "curs.execute(dataset_sql)\n",
    "dataset_result = curs.fetchall()\n",
    "curs.execute(grid_sql)\n",
    "grid_result = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "animal-princess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid</th>\n",
       "      <th>CCTV_num</th>\n",
       "      <th>police_value</th>\n",
       "      <th>resident</th>\n",
       "      <th>floating</th>\n",
       "      <th>crime_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>1102</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>1880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>1105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>1880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>1860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1107 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      grid  CCTV_num  police_value  resident  floating  crime_num\n",
       "0        0         0             0        20       170          0\n",
       "1        1         0             0        30       200          0\n",
       "39       2         0             0        20       260          1\n",
       "3        3         0             0        20       160          0\n",
       "4        4         0             0        40       170          0\n",
       "...    ...       ...           ...       ...       ...        ...\n",
       "1102  1102         8             0       310      1800          0\n",
       "1103  1103         0             0       330      1800          0\n",
       "1104  1104         0             0       450      1880          0\n",
       "1105  1105         0             0       240      1880          0\n",
       "1106  1106         0             0       280      1860          0\n",
       "\n",
       "[1107 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform to Pandas Dataframe\n",
    "import pandas as pd\n",
    "dataset_result = pd.DataFrame(dataset_result)\n",
    "grid_result = pd.DataFrame(grid_result)\n",
    "result = pd.concat([dataset_result, grid_result])\n",
    "result['crime_num'] = result.groupby(['grid']).grid.transform('count') -1\n",
    "result = result.drop_duplicates()\n",
    "result = result.sort_values('grid')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cosmetic-disney",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.940113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.937853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.938983</td>\n",
       "      <td>16061</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.932203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.938983</td>\n",
       "      <td>16061</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.932203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.940113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.937853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.938983</td>\n",
       "      <td>16061</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.932203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22731</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_leaf': 29, 'min...</td>\n",
       "      <td>0.940113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.937853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22732</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_leaf': 29, 'min...</td>\n",
       "      <td>0.940113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.937853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22733</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_leaf': 29, 'min...</td>\n",
       "      <td>0.940113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.937853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22734</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_leaf': 29, 'min...</td>\n",
       "      <td>0.940113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.937853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22735</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_leaf': 29, 'min...</td>\n",
       "      <td>0.940113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.937853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22736 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  params  mean_test_score  \\\n",
       "0      {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...         0.940113   \n",
       "1      {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...         0.938983   \n",
       "2      {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...         0.938983   \n",
       "3      {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...         0.940113   \n",
       "4      {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...         0.938983   \n",
       "...                                                  ...              ...   \n",
       "22731  {'max_depth': 30, 'min_samples_leaf': 29, 'min...         0.940113   \n",
       "22732  {'max_depth': 30, 'min_samples_leaf': 29, 'min...         0.940113   \n",
       "22733  {'max_depth': 30, 'min_samples_leaf': 29, 'min...         0.940113   \n",
       "22734  {'max_depth': 30, 'min_samples_leaf': 29, 'min...         0.940113   \n",
       "22735  {'max_depth': 30, 'min_samples_leaf': 29, 'min...         0.940113   \n",
       "\n",
       "       rank_test_score  split0_test_score  split1_test_score  \\\n",
       "0                    1           0.943503           0.943503   \n",
       "1                16061           0.943503           0.943503   \n",
       "2                16061           0.943503           0.943503   \n",
       "3                    1           0.943503           0.943503   \n",
       "4                16061           0.943503           0.943503   \n",
       "...                ...                ...                ...   \n",
       "22731                1           0.943503           0.943503   \n",
       "22732                1           0.943503           0.943503   \n",
       "22733                1           0.943503           0.943503   \n",
       "22734                1           0.943503           0.943503   \n",
       "22735                1           0.943503           0.943503   \n",
       "\n",
       "       split2_test_score  \n",
       "0               0.937853  \n",
       "1               0.932203  \n",
       "2               0.932203  \n",
       "3               0.937853  \n",
       "4               0.932203  \n",
       "...                  ...  \n",
       "22731           0.937853  \n",
       "22732           0.937853  \n",
       "22733           0.937853  \n",
       "22734           0.937853  \n",
       "22735           0.937853  \n",
       "\n",
       "[22736 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz  # DecisionTree 모듈, 시각화 모듈\n",
    "from sklearn.model_selection import train_test_split  # train, test dataset 분류\n",
    "from sklearn.model_selection import GridSearchCV # cross validation, hyper parameter\n",
    "from collections import Counter # 라벨 분포 확인\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import pydot\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "# Decision tree Classifier 생성\n",
    "\n",
    "# 학습해야하는 변수\n",
    "data = result[[\"CCTV_num\", \"police_value\", \"resident\", \"floating\"]].to_numpy()\n",
    "# 맞춰야하는 변수: crime_num\n",
    "target = result.crime_num.to_numpy()\n",
    "\n",
    "# dataset 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=10)\n",
    "\n",
    "# 하이퍼 파라미터 찾기\n",
    "tree = DecisionTreeClassifier()\n",
    "parameters = {'max_depth' : [x for x in range(3, 31, 1)], 'min_samples_leaf' : [x for x in range(1, 30, 1)], 'min_samples_split' : [x for x in range(2, 30, 1)]}\n",
    "\n",
    "# param_grid의  하이퍼 파라미터를 5개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "## refit=True가 기본 설정으로 True이면 가장 좋은 파라미터 설정으로 재학습 시킴\n",
    "grid_dtree = GridSearchCV(tree, param_grid=parameters, cv=5, refit=True)\n",
    "\n",
    "#학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습, 평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 데이터 프레임으로 반환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mobile-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch 최적 파라미터:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "GridSearch 최고 점수:  0.9401129943502825\n",
      "테스트 데이터세트 정확도:  0.9279\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('GridSearch 최적 파라미터: ', grid_dtree.best_params_)\n",
    "print('GridSearch 최고 점수: ', grid_dtree.best_score_)\n",
    "\n",
    "# GridSearchCV의 refit으로 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estmator_ 는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
    "pred = estimator.predict(X_test)\n",
    "\n",
    "# Confusion Matirx를 이용한 정확도 평가\n",
    "\n",
    "print('테스트 데이터세트 정확도: {0: .4f}'.format(accuracy_score(y_test, pred)))\n",
    "total = 0\n",
    "for i in range(pred.size):\n",
    "    if pred[i] >= y_test[i] - 3 and pred[i] <= y_test[i] + 3:\n",
    "        total += 1\n",
    "accuracy = total/pred.size\n",
    "\n",
    "\n",
    "# predic test_set labels\n",
    "y_pred = estimator.predict(data)\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "# 시각화를 위해 학습에 사용한 feature 라벨 추출\n",
    "feature_names = result.columns.tolist()\n",
    "feature_names = feature_names[1:5]\n",
    "# 트리 시각화\n",
    "dot_data = export_graphviz(estimator, out_file=\"1_1_1_DecisionTree.dot\", feature_names = feature_names, filled=True, rounded=True, special_characters=True)\n",
    "# 인코딩\n",
    "(graph,) = pydot.graph_from_dot_file(\"1_1_1_DecisionTree.dot\", encoding='utf8')\n",
    "# png로 저장\n",
    "graph.write_png(\"1_1_1_DecisionClass.png\") \n",
    "\n",
    "# 전체 Grid의 범죄 발생 확률 구하기\n",
    "total = np.sum(y_pred)\n",
    "result_prob = y_pred / total\n",
    "#print(result_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-classification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-broadcast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeRegressor - 최적 depth 뽑기\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz  # DecisionTree 모듈, 시각화 모듈\n",
    "from sklearn.model_selection import train_test_split  # train, test dataset 분류\n",
    "from collections import Counter # 라벨 분포 확인\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm_notebook\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# 학습해야하는 변수\n",
    "data = result[[\"CCTV_num\", \"police_value\", \"resident\", \"floating\"]].to_numpy()\n",
    "# 맞춰야하는 변수: crime_num\n",
    "target = result.crime_num.to_numpy()\n",
    "\n",
    "# dataset 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=10)\n",
    "\n",
    "# 데이터 분할 상태 확인\n",
    "print('train set: ', Counter(y_train))\n",
    "print('test set: ', Counter(y_test), '\\n')\n",
    "\n",
    "train_arr = []\n",
    "test_arr = []\n",
    "grid_arr = []\n",
    "RMSE_arr = []\n",
    "\n",
    "for k in tqdm_notebook(range(1, 21)):\n",
    "    \n",
    "    # X_train, Y_train 입력해 모델 생성, 학습 - Gini 계수\n",
    "    tree = DecisionTreeRegressor(random_state=42, max_depth=k, criterion='mse', splitter='best')\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "    \n",
    "    # 정확도 측정 - RMSE 측정\n",
    "    y_pred = tree.predict(data)\n",
    "    mse_dt = MSE(target, y_pred)\n",
    "    rmse_dt = mse_dt**(1/2)\n",
    "    RMSE_arr.append(rmse_dt)\n",
    "    \n",
    "    # train set 정확도 확인\n",
    "    Y_pred = np.around(tree.predict(X_train))\n",
    "    train_accuracy = 0\n",
    "    for i in range(len(X_train)):\n",
    "        if Y_pred[i] == y_train[i]:\n",
    "            train_accuracy += 1\n",
    "    train_accuracy = round(train_accuracy / len(X_train),3)\n",
    "    train_arr.append(train_accuracy)\n",
    "    \n",
    "    # test set 정확도 확인\n",
    "    Y_pred = np.around(tree.predict(X_test))\n",
    "    test_accuracy = 0\n",
    "    for i in range(len(X_test)):\n",
    "        if Y_pred[i] == y_test[i]:\n",
    "            test_accuracy += 1\n",
    "    test_accuracy = round(test_accuracy / len(X_test),3)\n",
    "    test_arr.append(test_accuracy)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(train_arr, label='train', color='green')\n",
    "plt.plot(test_arr, label='test', color='blue')\n",
    "plt.plot(RMSE_arr, label='RMSE', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree Regressor 생성\n",
    "\n",
    "import pydot\n",
    "# decision tree Regresssor 생성\n",
    "tree = DecisionTreeRegressor(random_state = 42, criterion = 'mse', splitter = 'best', max_depth = 4)\n",
    "# 모델 생성\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# predic test_set labels\n",
    "y_pred = tree.predict(data)\n",
    "# Compute test-set RMS\n",
    "mse_dt = MSE(target, y_pred)\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "# Print rmse_dt\n",
    "print(\"Grid RMSE: \", rmse_dt, '\\n')\n",
    "\n",
    "# 정확도 확인\n",
    "Y_pred = np.around(tree.predict(X_train))\n",
    "test_accuracy = 0\n",
    "for i in range(len(X_train)):\n",
    "    if Y_pred[i] == y_train[i]:\n",
    "        test_accuracy += 1\n",
    "test_accuracy = round(test_accuracy / len(X_train),3)\n",
    "print(\"내가 만든거: \", test_accuracy)\n",
    "#print(\"Train Set Accuracy: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "\n",
    "Y_pred = np.around(tree.predict(X_test))\n",
    "test_accuracy = 0\n",
    "for i in range(len(X_test)):\n",
    "    if Y_pred[i] == y_test[i]:\n",
    "        test_accuracy += 1\n",
    "test_accuracy = round(test_accuracy / len(X_test),3)\n",
    "print(\"내가 만든거: \", test_accuracy)\n",
    "#print(\"Test Set Accuracy: {:.3f}\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "# 시각화를 위해 학습에 사용한 feature 라벨 추출\n",
    "feature_names = result.columns.tolist()\n",
    "feature_names = feature_names[1:5]\n",
    "# 트리 시각화\n",
    "dot_data = export_graphviz(tree, out_file=\"1_1_1_DecisionTree.dot\", feature_names = feature_names, filled=True, rounded=True, special_characters=True)\n",
    "# 인코딩\n",
    "(graph,) = pydot.graph_from_dot_file(\"1_1_1_DecisionTree.dot\", encoding='utf8')\n",
    "# png로 저장\n",
    "graph.write_png(\"1_1_1_DecisionTreeRegress.png\") \n",
    "\n",
    "# 전체 Grid의 범죄 발생 확률 구하기\n",
    "total = np.sum(y_pred)\n",
    "result_prob = y_pred / total\n",
    "#print(result_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz # DecisionTree 회귀 모델, 시각화 모듈\n",
    "from sklearn.model_selection import train_test_split # train, test dataset 분류\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import pydot\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# 학습해야하는 변수\n",
    "data = result[[\"CCTV_num\", \"police_value\", \"resident\", \"floating\"]].to_numpy()\n",
    "# 맞춰야하는 변수: crime_num\n",
    "target = result.crime_num.to_numpy()\n",
    "\n",
    "# dataset 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=3)\n",
    "\n",
    "# 데이터 분할 상태 확인\n",
    "print('train set: ', Counter(y_train))\n",
    "print('test set: ', Counter(y_test), '\\n')\n",
    "\n",
    "# decision tree Regresssor 생성\n",
    "tree = DecisionTreeRegressor(random_state = 3, criterion = 'mse', splitter = 'best')\n",
    "# 모델 생성\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# predic test_set labels\n",
    "y_pred = tree.predict(data)\n",
    "# Compute test-set RMS\n",
    "mse_dt = MSE(target, y_pred)\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "# Print rmse_dt\n",
    "print(\"Grid RMSE: \", rmse_dt, '\\n')\n",
    "\n",
    "# 정확도 확인\n",
    "Y_pred = np.around(tree.predict(X_train))\n",
    "test_accuracy = 0\n",
    "for i in range(len(X_train)):\n",
    "    if Y_pred[i] == y_train[i]:\n",
    "        test_accuracy += 1\n",
    "test_accuracy = round(test_accuracy / len(X_train),3)\n",
    "print(\"내가 만든거: \", test_accuracy)\n",
    "print(\"Train Set Accuracy: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "\n",
    "Y_pred = np.around(tree.predict(X_test))\n",
    "test_accuracy = 0\n",
    "for i in range(len(X_test)):\n",
    "    if Y_pred[i] == y_test[i]:\n",
    "        test_accuracy += 1\n",
    "test_accuracy = round(test_accuracy / len(X_test),3)\n",
    "print(\"내가 만든거: \", test_accuracy)\n",
    "print(\"Test Set Accuracy: {:.3f}\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "# 시각화를 위해 학습에 사용한 feature 라벨 추출\n",
    "feature_names = result.columns.tolist()\n",
    "feature_names = feature_names[1:5]\n",
    "# 트리 시각화\n",
    "dot_data = export_graphviz(tree, out_file=\"1_1_1_DecisionTree.dot\", feature_names = feature_names, filled=True, rounded=True, special_characters=True)\n",
    "# 인코딩\n",
    "(graph,) = pydot.graph_from_dot_file(\"1_1_1_DecisionTree.dot\", encoding='utf8')\n",
    "# png로 저장\n",
    "graph.write_png(\"1_1_1_DecisionTreeRegress.png\") \n",
    "\n",
    "# 전체 Grid의 범죄 발생 확률 구하기\n",
    "total = np.sum(y_pred)\n",
    "result_prob = y_pred / total\n",
    "print(result_prob)\n",
    "\n",
    "\n",
    "# 그래프 시각화\n",
    "'''\n",
    "plt.figure()\n",
    "plt.plot(X_test, y_pred, color = 'cornflowerblue', label = 'test')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('target')\n",
    "plt.title('Decision Tree Regression')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ CCTV 수, 경찰서, 유동인구, 거주인구 Grid 번호 뽑기 ################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# select from Dataset\n",
    "sql = 'SELECT * FROM Grid;'\n",
    "curs.execute(sql)\n",
    "result = curs.fetchall()\n",
    "\n",
    "# Transform to Pandas Dataframe\n",
    "result = pd.DataFrame(result)\n",
    "\n",
    "# 필요한 데이터프레임만 뽑아오기\n",
    "total = result[[\"grid\", \"time\", \"CCTV_num\", \"police_value\", \"resident\", \"floating\"]]\n",
    "total = total.drop_duplicates([\"grid\", \"time\"])\n",
    "total = total.sort_values(by=['grid'], axis=0)\n",
    "\n",
    "# 평균값 구하기\n",
    "CCTV_num = result[\"CCTV_num\"]\n",
    "CCTV_num_mean = np.mean(CCTV_num).round()\n",
    "\n",
    "police_value = result[\"police_value\"]\n",
    "police_value_mean = np.mean(police_value).round()\n",
    "\n",
    "resident = result[\"resident\"]\n",
    "resident_mean = np.mean(resident).round()\n",
    "\n",
    "# 시간대별로 나누기\n",
    "morning_df = total.loc[total[\"time\"] == \"Morning\"]\n",
    "afternoon_df = total.loc[total[\"time\"] == \"Afternoon\"]\n",
    "evening_df = total.loc[total[\"time\"] == \"Evening\"]\n",
    "midnight_df = total.loc[total[\"time\"] == \"Midnight\"]\n",
    "\n",
    "# 시간대별 유동인구 평균값 구하기\n",
    "floating_mean = [np.mean(morning_df[\"floating\"]).round(), np.mean(afternoon_df[\"floating\"]).round(), np.mean(evening_df[\"floating\"]).round(), np.mean(midnight_df[\"floating\"]).round()]\n",
    "\n",
    "# 조건에 모두 만족하는 그리드 번호 추출\n",
    "grid_all = []\n",
    "morning_grid_all = (morning_df[(morning_df[\"CCTV_num\"] <= CCTV_num_mean) & (morning_df[\"police_value\"] <= police_value_mean) & (morning_df[\"resident\"] >= resident_mean) & (morning_df[\"floating\"] >= floating_mean[0])])[\"grid\"].values\n",
    "grid_all.append(morning_grid_all)\n",
    "\n",
    "afternoon_grid_all = (afternoon_df[(afternoon_df[\"CCTV_num\"] <= CCTV_num_mean) & (afternoon_df[\"police_value\"] <= police_value_mean) & (afternoon_df[\"resident\"] >= resident_mean) & (afternoon_df[\"floating\"] >= floating_mean[1])])[\"grid\"].values\n",
    "grid_all.append(afternoon_grid_all)\n",
    "\n",
    "evening_grid_all = (evening_df[(evening_df[\"CCTV_num\"] <= CCTV_num_mean) & (evening_df[\"police_value\"] <= police_value_mean) & (evening_df[\"resident\"] >= resident_mean) & (evening_df[\"floating\"] >= floating_mean[2])])[\"grid\"].values\n",
    "grid_all.append(evening_grid_all)\n",
    "\n",
    "midnight_grid_all = (midnight_df[(midnight_df[\"CCTV_num\"] <= CCTV_num_mean) & (midnight_df[\"police_value\"] <= police_value_mean) & (midnight_df[\"resident\"] >= resident_mean) & (midnight_df[\"floating\"] >= floating_mean[3])])[\"grid\"].values\n",
    "grid_all.append(midnight_grid_all)\n",
    "\n",
    "# 조건을 or로 만족하는 그리드 번호 추출\n",
    "grid_or = []\n",
    "morning_grid_or = (morning_df[((morning_df[\"CCTV_num\"] <= CCTV_num_mean) & (morning_df[\"police_value\"] <= police_value_mean)) | ((morning_df[\"resident\"] >= resident_mean) & (morning_df[\"floating\"] >= floating_mean[0]))])[\"grid\"].values\n",
    "grid_or.append(morning_grid_or)\n",
    "\n",
    "afternoon_grid_or = (afternoon_df[((afternoon_df[\"CCTV_num\"] <= CCTV_num_mean) & (afternoon_df[\"police_value\"] <= police_value_mean)) | ((afternoon_df[\"resident\"] >= resident_mean) & (afternoon_df[\"floating\"] >= floating_mean[1]))])[\"grid\"].values\n",
    "grid_or.append(afternoon_grid_or)\n",
    "\n",
    "evening_grid_or = (evening_df[((evening_df[\"CCTV_num\"] <= CCTV_num_mean) & (evening_df[\"police_value\"] <= police_value_mean)) | ((evening_df[\"resident\"] >= resident_mean) & (evening_df[\"floating\"] >= floating_mean[2]))])[\"grid\"].values\n",
    "grid_or.append(evening_grid_or)\n",
    "\n",
    "midnight_grid_or = (midnight_df[((midnight_df[\"CCTV_num\"] <= CCTV_num_mean) & (midnight_df[\"police_value\"] <= police_value_mean)) | ((midnight_df[\"resident\"] >= resident_mean) & (midnight_df[\"floating\"] >= floating_mean[3]))])[\"grid\"].values\n",
    "grid_or.append(midnight_grid_or)\n",
    "\n",
    "for i in range(0, 4):\n",
    "    for x in grid_or[i]:\n",
    "        if x in grid_all[i]:\n",
    "            grid_or[i] = np.delete(grid_or[i], np.where(grid_or[i] == x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
